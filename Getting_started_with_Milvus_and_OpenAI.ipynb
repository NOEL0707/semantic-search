{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (0.27.4)\n",
      "Requirement already satisfied: pymilvus in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (2.2.7)\n",
      "Requirement already satisfied: datasets in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from openai) (2.26.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: grpcio<=1.53.0,>=1.49.1 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from pymilvus) (1.53.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from pymilvus) (4.22.3)\n",
      "Requirement already satisfied: ujson>=2.0.0 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from pymilvus) (4.0.2)\n",
      "Requirement already satisfied: mmh3>=2.0 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from pymilvus) (3.1.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from pymilvus) (1.5.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from datasets) (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from datasets) (1.20.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from aiohttp->openai) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from aiohttp->openai) (21.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.4->pymilvus) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\noel vincent\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai pymilvus datasets tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Milvus running we can setup our global variables:\n",
    "- HOST: The Milvus host address\n",
    "- PORT: The Milvus port number\n",
    "- COLLECTION_NAME: What to name the collection within Milvus\n",
    "- DIMENSION: The dimension of the embeddings\n",
    "- OPENAI_ENGINE: Which embedding model to use\n",
    "- openai.api_key: Your OpenAI account key\n",
    "- INDEX_PARAM: The index settings to use for the collection\n",
    "- QUERY_PARAM: The search parameters to use\n",
    "- BATCH_SIZE: How many texts to embed and insert at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "HOST = 'localhost'\n",
    "PORT = 19530\n",
    "COLLECTION_NAME = 'book_search'\n",
    "DIMENSION = 1536\n",
    "OPENAI_ENGINE = 'text-embedding-ada-002'\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "INDEX_PARAM = {\n",
    "    'metric_type':'L2',\n",
    "    'index_type':\"HNSW\",\n",
    "    'params':{'M': 8, 'efConstruction': 64}\n",
    "}\n",
    "\n",
    "QUERY_PARAM = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"ef\": 64},\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milvus\n",
    "This segment deals with Milvus and setting up the database for this use case. Within Milvus we need to setup a collection and index the collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, utility, FieldSchema, Collection, CollectionSchema, DataType\n",
    "\n",
    "# Connect to Milvus Database\n",
    "connections.connect(host=HOST, port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove collection if it already exists\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    utility.drop_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection which includes the id, title, and embedding.\n",
    "fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name='title', dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name='description', dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION)\n",
    "]\n",
    "schema = CollectionSchema(fields=fields)\n",
    "collection = Collection(name=COLLECTION_NAME, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index on the collection and load it.\n",
    "collection.create_index(field_name=\"embedding\", index_params=INDEX_PARAM)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "With Milvus up and running we can begin grabbing our data. Hugging Face Datasets is a hub that holds many different user datasets, and for this example we are using Skelebor's book dataset. This dataset contains title-description pairs for over 1 million books. We are going to embed each description and store it within Milvus along with its title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import list_datasets\n",
    "\n",
    "# print(list_datasets())\n",
    "\n",
    "# datasets download book_titles_and_descriptions_en_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import config\n",
    "\n",
    "config.HF_DATASETS_CACHE = \"C:/Users/noel vincent/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/noel vincent/Skelebor___parquet/Skelebor--book_titles_and_descriptions_en_clean-3596935b1d8a7747/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Download the dataset and only use the `train` portion (file is around 800Mb)\n",
    "dataset = load_dataset('Skelebor/book_titles_and_descriptions_en_clean', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the Data\n",
    "Now that we have our data on our machine we can begin embedding it and inserting it into Milvus. The embedding function takes in text and returns the embeddings in a list format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function that converts the texts to embeddings\n",
    "def embed(texts):\n",
    "    embeddings = openai.Embedding.create(\n",
    "        input=texts,\n",
    "        engine=OPENAI_ENGINE\n",
    "    )\n",
    "    return [x['embedding'] for x in embeddings['data']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next step does the actual inserting. Due to having so many datapoints, if you want to immidiately test it out you can stop the inserting cell block early and move along. Doing this will probably decrease the accuracy of the results due to less datapoints, but it should still be good enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:39<00:00, 45.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = [\n",
    "    [], # title\n",
    "    [], # description\n",
    "]\n",
    "\n",
    "# Embed and insert in batches\n",
    "for i in tqdm(range(0, 10000)):\n",
    "    data[0].append(dataset[i]['title'])\n",
    "    data[1].append(dataset[i]['description'])\n",
    "    if len(data[0]) % BATCH_SIZE == 0:\n",
    "        data.append(embed(data[1]))\n",
    "        collection.insert(data)\n",
    "        data = [[],[]]\n",
    "\n",
    "# Embed and insert the remainder \n",
    "if len(data[0]) != 0:\n",
    "    data.append(embed(data[1]))\n",
    "    collection.insert(data)\n",
    "    data = [[],[]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Database\n",
    "With our data safely inserted in Milvus, we can now perform a query. The query takes in a string or a list of strings and searches them. The resuts print out your provided description and the results that include the result score, the result title, and the result book description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def query(queries, top_k = 5):\n",
    "    if type(queries) != list:\n",
    "        queries = [queries]\n",
    "    res = collection.search(embed(queries), anns_field='embedding', param=QUERY_PARAM, limit = top_k, output_fields=['title', 'description'])\n",
    "    for i, hit in enumerate(res):\n",
    "        print('Description:', queries[i])\n",
    "        print('Results:')\n",
    "        for ii, hits in enumerate(hit):\n",
    "            print('\\t' + 'Rank:', ii + 1, 'Score:', hits.score, 'Title:', hits.entity.get('title'))\n",
    "            print(textwrap.fill(hits.entity.get('description'), 88))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: Book about a k-9 from europe\n",
      "Results:\n",
      "\tRank: 1 Score: 0.3047754466533661 Title: Bark M For Murder\n",
      "Who let the dogs out? Evildoers beware! Four of mystery fiction's top storytellers are\n",
      "setting the hounds on your trail -- in an incomparable quartet of crime stories with a\n",
      "canine edge. Man's (and woman's) best friends take the lead in this phenomenal\n",
      "collection of tales tense and surprising, humorous and thrilling: New York\n",
      "Timesbestselling author J.A. Jance's spellbinding saga of a scam-busting septuagenarian\n",
      "and her two golden retrievers; Anthony Award winner Virginia Lanier's pureblood thriller\n",
      "featuring bloodhounds and bloody murder; Chassie West's suspenseful stunner about a\n",
      "life-saving German shepherd and a ghastly forgotten crime; rising star Lee Charles\n",
      "Kelley's edge-of-your-seat yarn that pits an ex-cop/kennel owner and a yappy toy poodle\n",
      "against a craven killer.\n",
      "\n",
      "\tRank: 2 Score: 0.3122304677963257 Title: Hudson in Provence\n",
      "A year after we first met Hudson, the lovable mutt who moved to Paris, he's back and\n",
      "thirsting for adventure--this time in the glorious south of France. When his owner\n",
      "decides it's time to get away from the sweltering August heat of the big city, Hudson is\n",
      "eager to follow. But of course what is a dream vacation for his mistress proves anything\n",
      "but that for him. This city dog discovers he's flat-footed when it comes to herding\n",
      "sheep, has no snout for sniffing out truffles, and can barely pedal his bike when he\n",
      "gets into the Tour de France. It's only when he stops imitating the other dogs and\n",
      "follows his heart that he discovers his own unique talent. Children, Francophiles, and\n",
      "dog-lovers alike will fall in love all over again with the four-legged American ex-pat\n",
      "as he sniffs, barks, and digs his way through Provence. Along the way, they'll bask in\n",
      "exquisite artwork that depicts Hudson and Provence in gorgeous hues with a painterly\n",
      "touch that perfectly complements the narrative. Gouache paintings of mountains and\n",
      "beaches, town squares and lavender fields, and dogs--beagles, boxers and border collies\n",
      "--lots of them!--evoke all the scents and scenery of Provence. A petit\n",
      "dictionnaireserves as an introduction to French for young and old alike.\n",
      "\n",
      "\tRank: 3 Score: 0.32286494970321655 Title: Two Dogs At The One Dog Inn And Other Stories\n",
      "The novella: Dogs are reported for their constant barking ... and so begins one of the\n",
      "strangest stories you will ever read. Audrey Ackerman, sent to visit the dogs at a 17th\n",
      "century coach house, is unsettled by paranormal sightings. Stella Bridgeport - manager\n",
      "at The Animal Welfare Union - communicates with Audrey via emails. And those Stella\n",
      "receives are as startling as they are incredible: descriptions of extraordinary events\n",
      "concerning a science fiction writer's journal; giant swans; bizarre android\n",
      "receptionist; a ghost dog. Insanity or fantasy? Fact or fiction? The only given is, it\n",
      "all starts and ends with two dogs at The One Dog Inn. ...and other stories: 12 short\n",
      "stories with aspects of the macabre, the surreal or the strangeness of magical realism\n",
      "to entertain and delight you.\n",
      "\n",
      "\tRank: 4 Score: 0.32838183641433716 Title: Texas K-9 Unit Christmas: Holiday Hero\\Rescuing Christmas\n",
      "CHRISTMAS COMES WRAPPED IN DANGER Holiday Hero by Shirlee McCoy Emma Fairchild never\n",
      "expected to find trouble in sleepy Sagebrush, Texas. But when she's attacked and left\n",
      "for dead in her own diner, her childhood friend turned K-9 cop Lucas Harwood offers a\n",
      "chance at justice--and love. Rescuing Christmas by Terri Reed She escaped a kidnapper,\n",
      "but now a killer has set his sights on K-9 dog trainer Lily Anderson. When fellow\n",
      "officer Jarrod Evans appoints himself her bodyguard, Lily knows more than her life is at\n",
      "risk--so is her heart. Texas K-9 Unit: These lawmen solve the toughest cases with the\n",
      "help of their brave canine partners\n",
      "\n",
      "\tRank: 5 Score: 0.3303978741168976 Title: Boss Dog: A Story of Provence\n",
      "Chronicles an American mother's year abroad with her two daughters in Aix-en-Provence.\n",
      "Part memoir and part fiction, this adventure is presided over by an aloof and\n",
      "proprietary mongrel, the Boss Dog, who frequents the young family's favorite cafe.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query('Book about a k-9 from europe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "10000\n",
      "[0.23534697344317268, 0.12981984750568643]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "data = [\n",
    "  [i for i in range(2000)],\n",
    "  [str(i) for i in range(2000)],\n",
    "  [i for i in range(10000, 12000)],\n",
    "  [[random.random() for _ in range(2)] for _ in range(2000)],\n",
    "]\n",
    "print(data[0][0])\n",
    "print(data[1][0])\n",
    "print(data[2][0])\n",
    "print(data[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
